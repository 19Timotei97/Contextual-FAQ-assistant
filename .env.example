ACCESS_TOKEN_EXPIRE_MINUTES=<desired_token_expiration_time_in_minutes>
ALGORITHM=<desired_algorithm_for_token_generation>
BATCH_SIZE=<desired_batch_size_for_vector_search>
CELERY_BROKER_URL=<desired_celery_message_broker_url>
CELERY_RESULT_BACKEND=<desired_celery_result_backend_url>
FAQ_COLLECTION_NAME=<desired_database_collection_name>
OPENAI_API_KEY=<your_openai_api_key>
OPENAI_MODEL_NAME=<desired_openai_model_name>
OPENAI_MODEL_MAX_TOKENS=<desired_max_tokens_for_openai_model>
OPENAI_MODEL_N=<desired_chat_completion_n>
OPENAI_MODEL_TEMPERATURE=<desired_model_temperature>
POSTGRES_DB=<desired_database_name>
POSTGRES_USER=<desired_database_username>
POSTGRES_PASSWORD=<desired_database_user_password>
POSTGRES_HOST=db # use the service name `db` defined in the docker-compose.yml file
POSTGRES_PORT=5432 # default port
PYTHONPATH=/app # set the project root directory as the Python path for imports to work
SECRET_KEY=<randomly_generated_secret_key_for_token_generation>
SIMILARITY_THRESHOLD=<desired_similarity_threshold>